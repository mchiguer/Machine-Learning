{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, I will be using one of the classification tasks found in OpenML. More precisely, the task [*bank marketing*](https://www.openml.org/search?type=data&id=1461) (data_id=1461) is selected. The classification goal of this task is to predict whether the client will subscribe a term deposit. The input features are numeric (age, account balance, etc.) and nominal (job, marital, education, etc.) types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can find a baseline result achieved with the logistic regression classifier using default parameters devoting 90% to training and 10% to test (random_state=23)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error:  10.8%\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\"); import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data_id = 1461\n",
    "test_size = 0.1\n",
    "X, y = fetch_openml(data_id=data_id, return_X_y=True, as_frame=False, parser=\"liac-arff\")\n",
    "# Default parameter values: tol=1e-4, C=1e0, solver='lbfgs', max_iter=1e2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=23)\n",
    "clf = LogisticRegression(random_state=23).fit(X_train, y_train)\n",
    "print(f'Test error: {(1 - accuracy_score(y_test, clf.predict(X_test)))*100:5.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Reg Classifier\n",
    "\n",
    "Applying the logistic regression classifier with default parameter values except for the parameter C, explore the values of the parameter C in logarithmic scale to determine an optimal value. Report classification error rate on training and test sets. Use random_state=23. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   solver     tol       C max_iter   etr   ete\n",
      "--------- ------- ------- -------- ----- -----\n",
      "    lbfgs 1.0e-04 1.0e-03      100 11.3% 10.9%\n",
      "    lbfgs 1.0e-04 1.0e-02      100 11.3% 10.8%\n",
      "    lbfgs 1.0e-04 1.0e-01      100 11.3% 10.8%\n",
      "    lbfgs 1.0e-04 1.0e+00      100 11.3% 10.8%\n",
      "    lbfgs 1.0e-04 1.0e+01      100 11.3% 10.8%\n",
      "    lbfgs 1.0e-04 1.0e+02      100 11.3% 10.8%\n",
      "    lbfgs 1.0e-04 1.0e+03      100 11.3% 10.8%\n"
     ]
    }
   ],
   "source": [
    "print('   solver     tol       C max_iter   etr   ete')\n",
    "print('--------- ------- ------- -------- ----- -----')\n",
    "for solver in ['lbfgs']:\n",
    "    for tol in [1e-4]:\n",
    "        for C in [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]:\n",
    "            for max_iter in [100]:\n",
    "                clf = LogisticRegression(solver=solver, tol=tol, C=C, max_iter=max_iter, random_state=23).fit(X_train, y_train)\n",
    "                etr = 1 - accuracy_score(y_train, clf.predict(X_train))\n",
    "                ete = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "                print(f'{solver:>9} {tol:.1e} {C:.1e} {max_iter:8d} {etr:5.1%} {ete:5.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the logistic regression classifier with default parameter values except for maximum number of iterations and the parameter C that should be fixed to the best value determined before, explore the maximum number of iterations in logarithmic scale to determine an optimal value. Report classification error rate on training and test sets. Use random_state=23. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   solver     tol       C max_iter   etr   ete\n",
      "--------- ------- ------- -------- ----- -----\n",
      "    lbfgs 1.0e-04 1.0e+01      100 11.3% 10.8%\n",
      "    lbfgs 1.0e-04 1.0e+01      200 11.2% 10.5%\n",
      "    lbfgs 1.0e-04 1.0e+01      500 11.2% 10.4%\n",
      "    lbfgs 1.0e-04 1.0e+01     1000 11.1% 10.1%\n",
      "    lbfgs 1.0e-04 1.0e+01     2000 11.1% 10.2%\n",
      "    lbfgs 1.0e-04 1.0e+01     5000 11.0% 10.2%\n",
      "    lbfgs 1.0e-04 1.0e+01    10000 11.0% 10.2%\n"
     ]
    }
   ],
   "source": [
    "print('   solver     tol       C max_iter   etr   ete')\n",
    "print('--------- ------- ------- -------- ----- -----')\n",
    "for solver in ['lbfgs']:\n",
    "    for tol in [1e-4]:\n",
    "        for C in [1e1]:\n",
    "            for max_iter in [100, 200, 500, 1000, 2000, 5000, 10000]:\n",
    "                clf = LogisticRegression(solver=solver, tol=tol, C=C, max_iter=max_iter, random_state=23).fit(X_train, y_train)\n",
    "                etr = 1 - accuracy_score(y_train, clf.predict(X_train))\n",
    "                ete = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "                print(f'{solver:>9} {tol:.1e} {C:.1e} {max_iter:8d} {etr:5.1%} {ete:5.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the logistic regression classifier with default parameter values except for the solver, the maximum number of iterations and the parameter C. Use the optimal value for the maximum number of iterations and parameter C determined in the previous experiments. Explore different solvers. Report classification error rate on training and test sets. Use random_state=23. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         solver     tol       C max_iter   etr   ete\n",
      "--------------- ------- ------- -------- ----- -----\n",
      "          lbfgs 1.0e-04 1.0e+01     5000 11.0% 10.2%\n",
      "      liblinear 1.0e-04 1.0e+01     5000 11.0% 10.3%\n",
      "      newton-cg 1.0e-04 1.0e+01     5000 11.0% 10.2%\n",
      "newton-cholesky 1.0e-04 1.0e+01     5000 11.0% 10.2%\n",
      "            sag 1.0e-04 1.0e+01     5000 11.3% 10.8%\n",
      "           saga 1.0e-04 1.0e+01     5000 11.3% 10.8%\n"
     ]
    }
   ],
   "source": [
    "print('         solver     tol       C max_iter   etr   ete')\n",
    "print('--------------- ------- ------- -------- ----- -----')\n",
    "for solver in ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']:\n",
    "    for tol in [1e-4]:\n",
    "        for C in [1e1]:\n",
    "            for max_iter in [5000]:\n",
    "                clf = LogisticRegression(solver=solver, tol=tol, C=C, random_state=23, max_iter=max_iter).fit(X_train, y_train)\n",
    "                etr = 1 - accuracy_score(y_train, clf.predict(X_train))\n",
    "                ete = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "                print(f'{solver:>15} {tol:.1e} {C:.1e} {max_iter:8d} {etr:5.1%} {ete:5.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results you have obtained, could you claim that this task is linearly separable? why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, the classification error rates achieved are far from zero, so I suspect that this task is not linearly separable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
